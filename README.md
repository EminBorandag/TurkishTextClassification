The current study focused on ML algorithms named NB, SMO, KNN, J48,RF, DL algorithms named CNN,LSTM,GRU, WEm algorithms named Doc2Vec, Word2Vec, Glove, FastText and TL algorithms named Bert,RoBERTa, BerTURK to classify Turkish texts using three separate data sets to measure the text classification performance in the Turkish language. 
It also developed a new method named LSRM to improve the text classification performance for agglutinative languages, such as the Turkish language, and tested this method on three different data sets. The following is the list of additional contributions of the study to the current literature.
The study ran different ML, DL and TL algorithms individually on data sets containing Turkish texts and calculated classification success rates for comparison. The study ran WEm algorithms, such as Word2Vec, Doc2Vec, and Glove, together with DL algorithms and calculated success rates from the datasets to identify whether vectorization methods improve the classification performance.
The study added a novel data set to the body of literature since few Turkish text classification datasets were available. It also prepared the new dataset to reflect the variations in Turkish word usage structure across time, as the data set included timestamp-enabled data. The study made available all datasets, models, and application codes used in the study to other researchers and also granted public access authorization.




